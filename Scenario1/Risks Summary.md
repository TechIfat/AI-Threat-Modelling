| Risk ID | Description | Severity | Likelihood | Impact | Mitigation Plan |
|---------|-------------|----------|------------|--------|-----------------|
| AI-R1 | Prompt injection leading to unauthorized data access | Critical | High | High | Implement advanced prompt sanitization and input validation |
| AI-R2 | Model poisoning through contaminated training data | High | Medium | High | Establish secure ML pipeline with data validation |
| AI-R3 | Identity spoofing using AI-generated content | High | Medium | High | Deploy multi-modal authentication and deepfake detection |
| AI-R4 | Sensitive data exfiltration via crafted prompts | Critical | High | High | Implement output filtering and data loss prevention |
| AI-R5 | Supply chain compromise of foundation models | Medium | Low | High | Conduct security assessment of all AI dependencies |
| AI-R6 | Adversarial attacks on model inference | High | High | Medium | Deploy adversarial detection and model hardening |
| AI-R7 | Context poisoning in vector databases | High | Medium | High | Implement vector validation and access controls |
| AI-R8 | Model inversion attacks exposing training data | Medium | Medium | Medium | Apply differential privacy and model protection |
| AI-R9 | Insufficient AI audit logging and monitoring | High | Medium | High | Deploy comprehensive AI observability platform |
| AI-R10 | Weak role-based access control for AI features | High | High | High | Implement granular RBAC with AI context awareness |
